{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c249e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T17:55:13.027590Z",
     "iopub.status.busy": "2023-03-18T17:55:13.026599Z",
     "iopub.status.idle": "2023-03-18T17:55:13.038374Z",
     "shell.execute_reply": "2023-03-18T17:55:13.037683Z"
    },
    "papermill": {
     "duration": 0.021244,
     "end_time": "2023-03-18T17:55:13.041630",
     "exception": false,
     "start_time": "2023-03-18T17:55:13.020386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa358e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T17:55:13.050360Z",
     "iopub.status.busy": "2023-03-18T17:55:13.049910Z",
     "iopub.status.idle": "2023-03-18T17:55:17.486227Z",
     "shell.execute_reply": "2023-03-18T17:55:17.484770Z"
    },
    "papermill": {
     "duration": 4.444244,
     "end_time": "2023-03-18T17:55:17.489601",
     "exception": false,
     "start_time": "2023-03-18T17:55:13.045357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shared\n",
    "import xarray as xr\n",
    "from shared import open_dataset, save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702260bd",
   "metadata": {
    "papermill": {
     "duration": 0.002297,
     "end_time": "2023-03-18T17:55:17.494313",
     "exception": false,
     "start_time": "2023-03-18T17:55:17.492016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load and aggregate AR6 FACTS projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a6c1ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-18T17:55:17.501597Z",
     "iopub.status.busy": "2023-03-18T17:55:17.500994Z"
    },
    "papermill": {
     "duration": 449.112487,
     "end_time": "2023-03-18T18:02:46.608838",
     "exception": false,
     "start_time": "2023-03-18T17:55:17.496351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_ds = []\n",
    "global_ds = []\n",
    "global_ssps = []\n",
    "\n",
    "\n",
    "def open_and_convert(ds_path):\n",
    "    out = open_dataset(ds_path)\n",
    "    out[\"sea_level_change\"] = (\n",
    "        out.sea_level_change.pint.quantify().pint.to(\"meters\").pint.dequantify()\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "for kind in [\"total\", \"verticallandmotion\"]:\n",
    "    ds = []\n",
    "    this_ssps = []\n",
    "    for conf in [\"low\", \"medium\"]:\n",
    "        for ds_path in (shared.DIR_SLR_AR6_RAW / \"regional\").glob(f\"{kind}_*_{conf}_*\"):\n",
    "            this_ssp = ds_path.name.split(\"_\")[1]\n",
    "            ssp_conf = f\"{this_ssp}_{conf}\"\n",
    "            ds.append(open_and_convert(ds_path))\n",
    "            this_ssps.append(ssp_conf)\n",
    "            if kind == \"total\":\n",
    "                global_ds.append(\n",
    "                    open_and_convert(shared.DIR_SLR_AR6_RAW / \"global\" / ds_path.name)\n",
    "                )\n",
    "                global_ssps.append(ssp_conf)\n",
    "    all_ds.append(\n",
    "        xr.concat(ds, pd.Index(this_ssps, name=\"scenario\"), data_vars=\"different\")\n",
    "    )\n",
    "\n",
    "# for some reason the VLM dataset has an entry for 2005 that is all 0s, while other\n",
    "# datasets just don't have 2005 b/c it is the assumed basline\n",
    "assert (all_ds[1].sea_level_change.sel(years=2005) == 0).all()\n",
    "all_ds[1] = all_ds[1].sel(years=slice(2006, None))\n",
    "\n",
    "global_ds = (\n",
    "    xr.concat(global_ds, pd.Index(global_ssps, name=\"scenario\"), data_vars=\"different\")\n",
    "    .squeeze(drop=True)\n",
    "    .drop_vars([\"lon\", \"lat\"])\n",
    "    .sea_level_change\n",
    ")\n",
    "\n",
    "# handle floating point matching errors on the quantile dimension\n",
    "global_ds[\"quantiles\"] = all_ds[0].quantiles\n",
    "all_ds[1][\"quantiles\"] = all_ds[0].quantiles\n",
    "\n",
    "all_ds = xr.Dataset(\n",
    "    {\n",
    "        \"lsl_msl05\": all_ds[0].sea_level_change,\n",
    "        \"lsl_ncc_msl05\": all_ds[1].sea_level_change,\n",
    "        \"gsl_msl05\": global_ds,\n",
    "        \"lon\": all_ds[1].lon,\n",
    "        \"lat\": all_ds[0].lat,\n",
    "    }\n",
    ")\n",
    "\n",
    "# drop locations with NaN values in the time period we're interested in\n",
    "valid = (\n",
    "    all_ds[[\"lsl_msl05\", \"lsl_ncc_msl05\"]]\n",
    "    .sel(years=slice(2100))\n",
    "    .notnull()\n",
    "    .all([\"scenario\", \"quantiles\", \"years\"])\n",
    "    .to_array(\"tmp\")\n",
    "    .all(\"tmp\")\n",
    ")\n",
    "all_ds = all_ds.sel(locations=valid)\n",
    "\n",
    "all_ds = all_ds.rename(\n",
    "    {\"years\": \"year\", \"quantiles\": \"quantile\", \"locations\": \"site_id\"}\n",
    ")\n",
    "\n",
    "# we generally allow +180 but not -180\n",
    "all_ds[\"lon\"] = all_ds.lon.where(all_ds.lon != -180, 180)\n",
    "\n",
    "# drop locations where we have missing values\n",
    "valid = all_ds.sel(year=slice(2100)).notnull().all([\"scenario\", \"quantile\", \"year\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471240b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351eb47b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for v in valid.variables:\n",
    "    valid[v].encoding.clear()\n",
    "save(valid.chunk({\"site_id\": 100}), shared.PATH_SLR_AR6, mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 457.941733,
   "end_time": "2023-03-18T18:02:48.273093",
   "environment_variables": {},
   "exception": null,
   "input_path": "data-processing/slr/AR6.ipynb",
   "output_path": "/Users/ianbolliger/git-repos/pyciam/notebooks/nb_logs/data-processing/slr/AR6.ipynb",
   "parameters": {},
   "start_time": "2023-03-18T17:55:10.331360",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}