{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run pyCIAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/dask_gateway/client.py:21: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import LoopRunner, format_bytes\n"
     ]
    }
   ],
   "source": [
    "import distributed as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from dask_gateway import Gateway\n",
    "from shared import (\n",
    "    AUTHOR,\n",
    "    CONTACT,\n",
    "    FS,\n",
    "    HISTORY,\n",
    "    PATH_PARAMS,\n",
    "    PATH_QUANTILE_RES,\n",
    "    PATH_REFA,\n",
    "    PATH_SLIIDERS_ECON,\n",
    "    PATH_SLIIDERS_SLR_QUANTILES,\n",
    "    PATH_SURGE_LOOKUP,\n",
    "    QUANTILES,\n",
    "    upload_pkg,\n",
    ")\n",
    "\n",
    "from pyCIAM.constants import CASE_DICT, CASES, COSTTYPES\n",
    "from pyCIAM.io import (\n",
    "    check_finished_zarr_workflow,\n",
    "    create_template_dataarray,\n",
    "    load_ciam_inputs,\n",
    "    save_to_zarr_region,\n",
    ")\n",
    "from pyCIAM.run import calc_costs, select_optimal_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TMPPATH = FS.get_mapper(\"rhg-data-scratch/pyCIAM_results_quantiles_prechunked.zarr\")\n",
    "\n",
    "N_WORKERS = 500\n",
    "SEG_CHUNKSIZE = 3\n",
    "\n",
    "DESCRIPTION = \"Projected coastal damages from pyCIAM, using quantiles of SLR scenarios.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8f11547a8748069e177ec8d461456f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>GatewayCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n<style scoped>\\n    â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gateway = Gateway()\n",
    "cluster = gateway.new_cluster(\n",
    "    idle_timeout=3600,\n",
    "    profile=\"micro\",\n",
    "    env_items={\n",
    "        \"DASK_DISTRIBUTED__SCHEDULER__ALLOWED_FAILURES\": \"10\",\n",
    "        \"DASK_DISTRIBUTED__WORKER__MEMORY__TARGET\": \"0.95\",\n",
    "        \"DASK_DISTRIBUTED__WORKER__MEMORY__SPILL\": \"0.95\",\n",
    "        \"DASK_DISTRIBUTED__WORKER__MEMORY__PAUSE\": \"0.95\",\n",
    "        \"DASK_DISTRIBUTED__WORKER__MEMORY__TERMINATE\": \"0.99\",\n",
    "    },\n",
    ")\n",
    "client = cluster.get_client()\n",
    "cluster.scale(N_WORKERS)\n",
    "\n",
    "client.upload_file(\"shared.py\")\n",
    "upload_pkg(client, \"../pyCIAM\")\n",
    "\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Template Zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coord values from input data\n",
    "params = pd.read_json(PATH_PARAMS)[\"values\"]\n",
    "ciam_in = xr.open_zarr(PATH_SLIIDERS_ECON, chunks=None)\n",
    "\n",
    "# set up coords and lengths\n",
    "coords = {\n",
    "    \"scenario\": np.concatenate(\n",
    "        ([\"ncc\"], xr.open_zarr(PATH_SLIIDERS_SLR_QUANTILES).scenario.values)\n",
    "    ),\n",
    "    \"quantile\": QUANTILES,\n",
    "    \"iam\": ciam_in.iam.values,\n",
    "    \"ssp\": ciam_in.ssp.values,\n",
    "    \"year\": ciam_in.year.values,\n",
    "    \"seg_adm\": ciam_in.seg_adm.values,\n",
    "    \"costtype\": COSTTYPES,\n",
    "    \"case\": CASES,\n",
    "}\n",
    "\n",
    "lens = {k: len(v) for k, v in coords.items()}\n",
    "\n",
    "chunks = {\"seg_adm\": 1, \"case\": len(coords[\"case\"]) - 1}\n",
    "chunks = {k: -1 if k not in chunks else chunks[k] for k in coords}\n",
    "\n",
    "# create arrays\n",
    "cost_dims = [\n",
    "    \"case\",\n",
    "    \"costtype\",\n",
    "    \"seg_adm\",\n",
    "    \"scenario\",\n",
    "    \"quantile\",\n",
    "    \"year\",\n",
    "    \"ssp\",\n",
    "    \"iam\",\n",
    "]\n",
    "refA_dims = [\"case\", \"seg_adm\", \"quantile\"]\n",
    "npv_dims = [\"ssp\", \"iam\", \"case\", \"seg_adm\", \"quantile\"]\n",
    "\n",
    "out_ds = create_template_dataarray(cost_dims, coords, chunks).to_dataset(name=\"costs\")\n",
    "out_ds[\"npv\"] = out_ds.costs.isel(year=0, costtype=0, drop=True).astype(\"float64\")\n",
    "out_ds[\"optimal_case\"] = out_ds.npv.isel(case=0, drop=True).astype(\"uint8\")\n",
    "\n",
    "# add attrs\n",
    "out_ds.attrs.update(\n",
    "    {\n",
    "        \"description\": DESCRIPTION,\n",
    "        \"author\": AUTHOR,\n",
    "        \"contact\": CONTACT,\n",
    "        \"history\": HISTORY,\n",
    "        \"updated\": pd.Timestamp.now(tz=\"US/Pacific\").strftime(\"%c\"),\n",
    "        \"planning_period_start_years\": params.at_start,\n",
    "    }\n",
    ")\n",
    "out_ds.costs.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Costs\",\n",
    "        \"description\": \"Cost (by cost type) incurred in a given time period\",\n",
    "        \"units\": \"2019 USD\",\n",
    "    }\n",
    ")\n",
    "out_ds.npv.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Net Present Value\",\n",
    "        \"description\": (\n",
    "            \"Calculated using 4% discount and inclusive of initial adaptation.\"\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "out_ds.optimal_case.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Lowest Cost Adaptation Approach\",\n",
    "        \"description\": \"Adaptation approach chosen by each segment\",\n",
    "        \"data_dictionary\": str(CASE_DICT),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('_finalize_store-95ee7d13-4d7e-4b58-a7c4-34552f121650')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save\n",
    "out_ds.to_zarr(TMPPATH, compute=False, mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define wrapper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_all_cases(\n",
    "    seg_adms,\n",
    "    check=True,\n",
    "):\n",
    "    if check_finished_zarr_workflow(\n",
    "        finalstore=TMPPATH if check else None,\n",
    "        varname=\"costs\",\n",
    "        final_selector={\"seg_adm\": seg_adms, \"case\": CASES[:-1]},\n",
    "    ):\n",
    "        return None\n",
    "\n",
    "    segs = [\"_\".join(seg_adm.split(\"_\")[:2]) for seg_adm in seg_adms]\n",
    "\n",
    "    inputs, slr, surge = load_ciam_inputs(\n",
    "        PATH_SLIIDERS_ECON,\n",
    "        PATH_SLIIDERS_SLR_QUANTILES,\n",
    "        params,\n",
    "        seg_adms,\n",
    "        seg_var=\"seg_adm\",\n",
    "        surge_lookup_store=PATH_SURGE_LOOKUP,\n",
    "    )\n",
    "\n",
    "    slr = slr.unstack().rename(mc_sample_id=\"quantile\")\n",
    "\n",
    "    # get initial adaptation height\n",
    "    refA = (\n",
    "        xr.open_zarr(PATH_REFA, chunks=None)\n",
    "        .refA.sel(seg=segs, movefactor=inputs.movefactor)\n",
    "        .drop_vars([\"case\", \"movefactor\"])\n",
    "    )\n",
    "    refA[\"seg\"] = seg_adms\n",
    "\n",
    "    out = (\n",
    "        calc_costs(\n",
    "            inputs,\n",
    "            slr,\n",
    "            surge_lookup=surge,\n",
    "            elev_chunksize=None,\n",
    "            min_R_noadapt=refA,\n",
    "            dmf_kwargs={\"floodmortality\": params.floodmortality},\n",
    "        )\n",
    "        .to_dataset(name=\"costs\")\n",
    "        .rename(seg=\"seg_adm\")\n",
    "    )\n",
    "\n",
    "    out[\"npv\"] = (\n",
    "        (out.costs.sum(\"costtype\") * inputs.dfact)\n",
    "        .sel(year=slice(inputs.npv_start, None))\n",
    "        .sum(\"year\")\n",
    "    )\n",
    "\n",
    "    save_to_zarr_region(out, TMPPATH)\n",
    "    return None\n",
    "\n",
    "\n",
    "def optimize_case(seg_adm, *wait_futs, check=True):\n",
    "    # use last fpath to check if this task has already been run\n",
    "    if check and check_finished_zarr_workflow(\n",
    "        finalstore=TMPPATH if check else None,\n",
    "        varname=\"costs\",\n",
    "        final_selector={\"seg_adm\": seg_adm, \"case\": CASES[-1]},\n",
    "    ):\n",
    "        return None\n",
    "\n",
    "    seg = \"_\".join(seg_adm.split(\"_\")[:2])\n",
    "    with xr.open_zarr(PATH_SLIIDERS_ECON, chunks=None) as ds:\n",
    "        all_segs = ds.seg.load()\n",
    "\n",
    "    this_seg_adms = all_segs.seg_adm.isel(seg_adm=all_segs.seg == seg).values\n",
    "\n",
    "    save_to_zarr_region(\n",
    "        select_optimal_case(TMPPATH, seg_adm, this_seg_adms, region_var=\"seg_adm\"),\n",
    "        TMPPATH,\n",
    "    )\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate initial adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get groups for running pyCIAM\n",
    "groups = [\n",
    "    ciam_in.seg_adm.isel(seg_adm=slice(i, i + SEG_CHUNKSIZE)).values\n",
    "    for i in np.arange(0, len(ciam_in.seg_adm), SEG_CHUNKSIZE)\n",
    "]\n",
    "\n",
    "# get groups for aggregating seg-adms up to segs\n",
    "most_segadm = ciam_in.seg.groupby(ciam_in.seg).count().max().item()\n",
    "i = 0\n",
    "agg_groups = []\n",
    "while i < len(ciam_in.seg):\n",
    "    this_group = ciam_in.isel(seg_adm=slice(i, i + most_segadm))\n",
    "    if len(np.unique(this_group.seg)) == 1:\n",
    "        i += most_segadm\n",
    "    else:\n",
    "        this_group = this_group.isel(\n",
    "            seg_adm=this_group.seg != this_group.seg.isel(seg_adm=-1, drop=True)\n",
    "        )\n",
    "        i += len(this_group.seg_adm)\n",
    "\n",
    "    agg_groups.append(this_group.seg_adm.values)\n",
    "\n",
    "groups_ser = (\n",
    "    pd.Series(groups)\n",
    "    .explode()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"group_id\", 0: \"seg_adm\"})\n",
    "    .set_index(\"seg_adm\")\n",
    "    .group_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run 1st stage (estimate costs for each adaptation type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "futs = np.array(client.map(calc_all_cases, groups, check=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Add optimal case data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seg_adms = ciam_in.seg_adm.values\n",
    "seg_adm_ser = pd.Series(seg_adms)\n",
    "seg_adm_ser.index = seg_adm_ser.str.split(\"_\").apply(lambda x: \"_\".join(x[:2]))\n",
    "seg_grps = seg_adm_ser.groupby(seg_adm_ser.index).apply(list)\n",
    "precurser_futs = (\n",
    "    seg_adm_ser.to_frame(\"seg_adm\")\n",
    "    .join(seg_grps.rename(\"seg_group\"))\n",
    "    .set_index(\"seg_adm\")\n",
    "    .seg_group.explode()\n",
    "    .to_frame()\n",
    "    .join(groups_ser, on=\"seg_group\")\n",
    "    .groupby(\"seg_adm\")\n",
    "    .group_id.apply(set)\n",
    "    .apply(list)\n",
    "    .apply(lambda x: futs[x])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "futs = precurser_futs.reset_index(drop=False).apply(\n",
    "    lambda row: client.submit(optimize_case, row.seg_adm, *row.group_id), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rechunk and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = dd.wait(futs.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = (\n",
    "    xr.open_zarr(TMPPATH, chunks={\"case\": -1, \"seg_adm\": 10})\n",
    "    .chunk({\"year\": 10})\n",
    "    .persist()\n",
    ")\n",
    "for v in out.data_vars:\n",
    "    out[v].encoding.clear()\n",
    "\n",
    "out[\"npv\"] = out.npv.astype(\"float32\")\n",
    "\n",
    "for k, v in out.coords.items():\n",
    "    if v.dtype == object:\n",
    "        out[k] = v.astype(\"unicode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7ff324d1ec80>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.to_zarr(PATH_QUANTILE_RES, mode=\"w\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shut down cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.close(), client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMPPATH.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
