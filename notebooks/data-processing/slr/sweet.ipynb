{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/dask_gateway/client.py:21: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import LoopRunner, format_bytes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shared\n",
    "import xarray as xr\n",
    "from shared import open_dataarray, open_dataset, open_zarr, save\n",
    "\n",
    "from pyCIAM import spherical_nearest_neighbor as snn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Sweet et al. datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global data\n",
    "glob = (\n",
    "    open_dataset(shared.DIR_SLR_SWEET_RAW / \"TR_global_projections.nc\")\n",
    "    .rename(years=\"year\", percentiles=\"quantile\")\n",
    "    .sel(year=slice(2020, None))[\n",
    "        [\"GMSL_Low\", \"GMSL_IntLow\", \"GMSL_Int\", \"GMSL_IntHigh\", \"GMSL_High\"]\n",
    "    ]\n",
    "    .to_array(dim=\"scenario\")\n",
    ")\n",
    "glob[\"scenario\"] = glob.scenario.str[5:]\n",
    "glob[\"quantile\"] = glob[\"quantile\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gauge data\n",
    "ds_loc = (\n",
    "    open_dataset(shared.DIR_SLR_SWEET_RAW / \"TR_local_projections.nc\")\n",
    "    .set_coords([\"lon\", \"lat\"])\n",
    "    .rename(percentiles=\"quantile\", years=\"year\", tg=\"site_id\")\n",
    "    .dropna(how=\"all\", dim=\"year\")\n",
    "    .sel(year=slice(2020, None))\n",
    ")\n",
    "\n",
    "# drop stations w/ QC issues\n",
    "ds_loc = ds_loc.sel(site_id=~ds_loc.QC_flag.astype(bool))\n",
    "\n",
    "# rearrange\n",
    "ds_loc = ds_loc[[i for i in ds_loc.data_vars if i.startswith(\"rsl_total\")]].to_array(\n",
    "    dim=\"scenario\"\n",
    ")\n",
    "ds_loc[\"quantile\"] = ds_loc[\"quantile\"] / 100\n",
    "ds_loc[\"scenario\"] = ds_loc.scenario.str[10:]\n",
    "assert ds_loc.notnull().all()\n",
    "\n",
    "# rename site ID as numeric\n",
    "ds_loc[\"site_id\"] = np.arange(ds_loc.site_id.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridded data\n",
    "grid = (\n",
    "    open_dataset(shared.DIR_SLR_SWEET_RAW / \"TR_gridded_projections.nc\")\n",
    "    .rename(percentiles=\"quantile\", years=\"year\")\n",
    "    .dropna(how=\"all\", dim=\"year\")\n",
    "    .sel(year=slice(2020, None))\n",
    "    .stack(site_id=[\"lon\", \"lat\"])\n",
    ")\n",
    "\n",
    "# rearrange\n",
    "grid = grid[[i for i in grid.data_vars if i.startswith(\"rsl_total\")]].to_array(\n",
    "    dim=\"scenario\"\n",
    ")\n",
    "grid[\"quantile\"] = grid[\"quantile\"] / 100\n",
    "grid[\"scenario\"] = grid.scenario.str[10:]\n",
    "\n",
    "# drop land pixels that are not valid\n",
    "grid = grid.sel(site_id=(grid != -31985).all([\"scenario\", \"quantile\", \"year\"]))\n",
    "assert grid.notnull().all()\n",
    "\n",
    "# rename site_id\n",
    "grid = grid.reset_index(\"site_id\").assign_coords(\n",
    "    site_id=np.arange(ds_loc.site_id.size, ds_loc.site_id.size + grid.site_id.size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we call these \"05\" even though they are currently relative to '00. Will convert next\n",
    "full = xr.Dataset(\n",
    "    {\n",
    "        \"lsl_msl05\": xr.concat((ds_loc, grid.interp(year=ds_loc.year)), \"site_id\"),\n",
    "        \"gsl_msl05\": glob,\n",
    "    }\n",
    ")\n",
    "assert full.lsl_msl05.notnull().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust to 2005 baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the LSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = (\n",
    "    open_dataarray(shared.PATH_SLR_HIST_TREND_MAP).rename(\n",
    "        longitude=\"lon\", latitude=\"lat\"\n",
    "    )\n",
    "    * 5\n",
    ")\n",
    "adj[\"lon\"] = adj.lon.where(adj.lon <= 180, adj.lon - 360)\n",
    "adj = adj.to_dataframe().dropna().reset_index()\n",
    "\n",
    "full_sites = full[[\"lon\", \"lat\"]].to_dataframe()\n",
    "full_sites[\"lon\"] = full_sites.lon.where(full_sites.lon <= 180, full_sites.lon - 360)\n",
    "\n",
    "vals = adj.loc[snn(full_sites, adj.reset_index()).values, \"sea_level_trends\"]\n",
    "vals.index = pd.Index(full.site_id.values, name=\"site_id\")\n",
    "\n",
    "full[\"lsl_msl05\"] -= vals.to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the GSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = open_dataset(shared.PATH_SLR_GMSL_HIST_TIMESERIES).msl.to_series()\n",
    "full[\"gsl_msl05\"] -= (\n",
    "    adj.loc[\"1996\":\"2014\"].mean() - adj.loc[\"1991\":\"2009\"].mean()\n",
    ") * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update to meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.lon.attrs.clear()\n",
    "full.lat.attrs.clear()\n",
    "full = (\n",
    "    full.pint.quantify(lsl_msl05=\"mm\", gsl_msl05=\"mm\")\n",
    "    .pint.to(lsl_msl05=\"meters\", gsl_msl05=\"meters\")\n",
    "    .pint.dequantify()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add NCC scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use AR6 VLM scenario for Sweet\n",
    "\n",
    "ar6 = open_zarr(shared.PATH_SLR_AR6)[[\"lon\", \"lat\", \"lsl_ncc_msl05\"]]\n",
    "\n",
    "aligned_sites = snn(\n",
    "    full_sites, ar6[[\"lon\", \"lat\"]].to_dataframe().reset_index(drop=True)\n",
    ").values\n",
    "full[\"lsl_ncc_msl05\"] = (\n",
    "    ar6.lsl_ncc_msl05.sel(quantile=full[\"quantile\"])\n",
    "    .isel(site_id=aligned_sites)\n",
    "    .interp(year=full.year)\n",
    "    .assign_coords(site_id=full.site_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.scenario.attrs.update(\n",
    "    {\n",
    "        \"description\": (\n",
    "            \"Scenarios are defined by their 2100 GMSL change relative to 2000. \"\n",
    "            \"Low=0.3m; IntLow=0.5m; Int=1.0m; IntHigh=1.5m; High=2.0m\"\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in full.variables:\n",
    "    full[v].encoding.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(full.chunk({\"site_id\": 100}), shared.PATH_SLR_SWEET, mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
