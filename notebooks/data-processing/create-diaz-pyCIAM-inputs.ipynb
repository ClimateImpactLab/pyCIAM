{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess pyCIAM Inputs for Diaz 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook creates all of the inputs needed for `pyCIAM`, using the data provided by the [github repo](https://github.com/delavane/CIAM) for [Diaz 2016](https://link.springer.com/article/10.1007/s10584-016-1675-4). The raw GAMS data files (.gdx) were previously converted to a zarr store for easy loading in pyCIAM. In this notebook, we reformat this zarr store and calculate some intermediate data products that were calculated on the fly in Diaz 2016 but are treated as input values in pyCIAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/dask_gateway/client.py:21: FutureWarning: format_bytes is deprecated and will be removed in a future release. Please use dask.utils.format_bytes instead.\n",
      "  from distributed.utils import LoopRunner, format_bytes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from shared import PATH_DIAZ_INPUTS_INT, PATH_DIAZ_INPUTS_RAW, open_zarr, save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, assuming missings (e.g. in land area) correspond to 0\n",
    "ds_in = open_zarr(PATH_DIAZ_INPUTS_RAW).load()\n",
    "for v in ds_in.data_vars:\n",
    "    if ds_in[v].isnull().any():\n",
    "        ds_in[v] = ds_in[v].fillna(0)\n",
    "\n",
    "# drop non-segment-level analysis inputs\n",
    "ds_in = ds_in.drop_vars(\n",
    "    [\n",
    "        d\n",
    "        for d in ds_in.data_vars\n",
    "        if d.startswith(\"country_\") or d.startswith(\"fund_\") or d.startswith(\"rep_\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust to \"remove kink in land area\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "area0 = ds_in.landarea.sel(elev=1) / 2\n",
    "area0[\"elev\"] = 0.5\n",
    "\n",
    "area2 = ds_in.landarea.sel(elev=2) / 2\n",
    "\n",
    "area1 = area0 + area2\n",
    "area1[\"elev\"] = 1.5\n",
    "\n",
    "landarea = xr.concat(\n",
    "    [area0, area1, area2, ds_in.landarea.sel(elev=slice(3, None))], dim=\"elev\"\n",
    ")\n",
    "ds_in = ds_in.drop_dims(\"elev\")\n",
    "ds_in[\"landarea\"] = landarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate input vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with coastline lengths\n",
    "out = xr.Dataset({\"length\": ds_in.length})\n",
    "\n",
    "# constants from original ciam dataset\n",
    "out = xr.merge((out, ds_in.mobcapfrac))\n",
    "\n",
    "# extreme sea levels\n",
    "esls = ds_in.surge_height.sel(return_period=[\"s10\", \"s100\", \"s1000\", \"smax\"])\n",
    "esls[\"return_period\"] = [10, 100, 1000, 10000]\n",
    "out[\"surge_height\"] = esls\n",
    "\n",
    "# growth values used later\n",
    "gr_ypcc = ds_in[\"ypc\"] / (ds_in[\"ypc\"].shift(t=1) + 1e-9) - 1\n",
    "gr_pop = ds_in[\"pop\"] / (ds_in[\"pop\"].shift(t=1) + 1e-9) - 1\n",
    "gr_val = xr.DataArray(np.arange(len(ds_in.t)), coords={\"t\": ds_in.t.values})\n",
    "appr = np.exp((0.565 * gr_ypcc + 0.313 * gr_pop).cumsum(\"t\"))\n",
    "\n",
    "# population\n",
    "popdens = ds_in.popdens * np.exp(np.log(1 + gr_pop).cumsum(\"t\")).sel(country=ds_in.xsc)\n",
    "out[\"pop_2000\"] = popdens.isel(t=0, drop=True) * ds_in.landarea.fillna(0)\n",
    "out[\"pop_scale\"] = (popdens / popdens.isel(t=0, drop=True)).fillna(0)\n",
    "\n",
    "# income\n",
    "out[\"ypc\"] = ds_in.ypc.sel(country=ds_in.xsc) * np.maximum(\n",
    "    ds_in.min_ypc_scale,\n",
    "    (popdens.isel(t=0, drop=True) / ds_in.ypc_scale_denom) ** ds_in.ypc_scale_elast,\n",
    ")\n",
    "# correct for greenland\n",
    "out[\"ypc\"] = out.ypc.where(\n",
    "    ~ds_in.subsets.sel(subset=\"greenland\", drop=True), 22642 * 1.01**gr_val\n",
    ")\n",
    "\n",
    "# capital\n",
    "out[\"K_2000\"] = ds_in.kgdp * out[\"pop_2000\"] * out.ypc.isel(t=0, drop=True)\n",
    "out[\"K_scale\"] = out.pop_scale * out.ypc / out.ypc.isel(t=0, drop=True)\n",
    "\n",
    "# land value\n",
    "fundland = (\n",
    "    np.minimum(\n",
    "        ds_in.dvbm,\n",
    "        np.maximum(\n",
    "            ds_in.min_fundland,\n",
    "            ds_in.dvbm\n",
    "            * ds_in.ypc.isel(t=0, drop=True)\n",
    "            * ds_in.refpopdens\n",
    "            / (\n",
    "                ds_in.ypc.isel(t=0, drop=True).sel(country=\"USA\", drop=True)\n",
    "                * ds_in.refpopdens.sel(country=\"USA\", drop=True)\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    * 1e6\n",
    ")\n",
    "interior = appr * fundland\n",
    "out[\"interior\"] = interior.where(\n",
    "    ~ds_in.subsets.sel(subset=\"greenland\", drop=True),\n",
    "    interior.sel(country=\"CAN\", drop=True),\n",
    ").sel(country=ds_in.xsc)\n",
    "\n",
    "# wetland - distribute this over total land area starting from elev=0 to emulate how it\n",
    "# is implicitly treated in calculating wetland costs in Diaz 2016\n",
    "cum_area = ds_in.landarea.cumsum(\"elev\")\n",
    "wetland_area = ds_in.landarea.where(\n",
    "    ds_in.wetland.fillna(0) >= cum_area,\n",
    "    np.maximum(ds_in.wetland.fillna(0) - cum_area.shift(elev=1, fill_value=0), 0),\n",
    ")\n",
    "wetlandservice = (\n",
    "    1e6\n",
    "    * appr\n",
    "    * ds_in.wvbm\n",
    "    * (\n",
    "        ds_in.ypc.isel(t=0, drop=True)\n",
    "        / ds_in.ypc.isel(t=0, drop=True).sel(country=\"USA\", drop=True)\n",
    "    )\n",
    "    ** 1.16\n",
    "    * (ds_in.refpopdens / 27.59) ** 0.47\n",
    ")\n",
    "out[\"wetland\"] = wetland_area\n",
    "out[\"wetlandservice\"] = wetlandservice.sel(country=ds_in.xsc)\n",
    "# handle segs where they have more wetland area than land area\n",
    "out[\"total_wetland_val\"] = ds_in.wetland.fillna(0) * wetlandservice.sel(\n",
    "    country=ds_in.xsc\n",
    ")\n",
    "\n",
    "# vsl\n",
    "out[\"vsl\"] = (\n",
    "    ds_in.vsl_ypc_mult\n",
    "    * ds_in.ypc.sel(country=\"USA\", drop=True)\n",
    "    * (ds_in.ypc / ds_in.ypc.sel(country=\"USA\", drop=True)) ** ds_in.vsl_inc_elast\n",
    ").sel(country=ds_in.xsc)\n",
    "# correct greenland\n",
    "out[\"vsl\"] = out.vsl.where(\n",
    "    ~ds_in.subsets.sel(subset=\"greenland\", drop=True),\n",
    "    (\n",
    "        ds_in.vsl_ypc_mult\n",
    "        * ds_in.ypc.sel(country=\"USA\", drop=True)\n",
    "        * (\n",
    "            out.ypc.isel(seg=ds_in.subsets.sel(subset=\"greenland\", drop=True))\n",
    "            / ds_in.ypc.sel(country=\"USA\", drop=True)\n",
    "        )\n",
    "        ** ds_in.vsl_inc_elast\n",
    "    ).reindex(seg=out.seg),\n",
    ")\n",
    "\n",
    "# rho\n",
    "out[\"rho\"] = (\n",
    "    ds_in.ypc\n",
    "    / (ds_in.ypc + ds_in.ypc.isel(t=0, drop=True).sel(country=\"USA\", drop=True))\n",
    ").sel(country=ds_in.xsc)\n",
    "\n",
    "# protection construction cost\n",
    "cci = ds_in.cci.sel(country=ds_in.xsc)\n",
    "cci = cci.where(~ds_in.subsets.sel(subset=\"island\", drop=True), cci * 2)\n",
    "out[\"pc\"] = ds_in.pc0 * 1e6 * cci\n",
    "\n",
    "# discount factor. emulating diaz, we don't discount 2010 relative to 2000 and start\n",
    "# discounting in 2010\n",
    "out[\"dr\"] = ds_in.dr\n",
    "out[\"dfact\"] = 1 / (1 + ds_in.dr) ** (out.t - out.t.isel(t=0, drop=True))\n",
    "\n",
    "# add in year 2000 values, equal to 2010\n",
    "out = out.reindex(t=np.concatenate(([2000], out.t.values))).bfill(\"t\")\n",
    "\n",
    "# add in surge coefficients to allow for Diaz-like surge calculation\n",
    "out[\"surge_coefs\"] = ds_in.coefs\n",
    "\n",
    "# add in LSL\n",
    "out[\"lsl\"] = ds_in.lsl.reindex(t=out.t.values, fill_value=0)\n",
    "\n",
    "# land area\n",
    "out[\"landarea\"] = ds_in.landarea.fillna(0)\n",
    "\n",
    "# add in elevation bounds\n",
    "elev_lb = xr.DataArray(\n",
    "    np.concatenate(([0, 0.5, 1.5], out.elev.isel(elev=slice(3, None)).values - 1)),\n",
    "    coords={\"elev\": out.elev.values},\n",
    ")\n",
    "out[\"elev_bounds\"] = xr.concat(\n",
    "    (elev_lb, out.elev), dim=pd.Index([\"lower\", \"upper\"], name=\"bound\")\n",
    ")\n",
    "out[\"elev\"] = out.elev_bounds.mean(\"bound\")\n",
    "\n",
    "# rename t\n",
    "out = out.rename(t=\"year\").drop_vars(\"country\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_units = \"2010 USD\"\n",
    "\n",
    "# coords\n",
    "out.seg.attrs.update({\"long_name\": \"DIVA Segment\"})\n",
    "out.return_period.attrs.update({\"long_name\": \"Return periods\", \"units\": \"y\"})\n",
    "out.elev.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Elevation\",\n",
    "        \"description\": (\n",
    "            \"Midpoint elevation for each coastal elevation bin employed in pyCIAM\"\n",
    "        ),\n",
    "        \"units\": \"m\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# data_vars\n",
    "out.surge_coefs.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Surge Damage Coefficients\",\n",
    "        \"description\": (\n",
    "            \"Coefficients used in the original Diaz 2016 paper to estimate surge \"\n",
    "            \"damage\"\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "out.elev_bounds.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Elevation bounds\",\n",
    "        \"description\": (\n",
    "            \"Lower and upper bounds for each coastal elevation bin employed in pyCIAM\"\n",
    "        ),\n",
    "        \"units\": \"m\",\n",
    "    }\n",
    ")\n",
    "out.length.attrs.update({\"description\": \"Length of coastline\", \"units\": \"km\"})\n",
    "out.surge_height.attrs.update(\n",
    "    {\"description\": \"Estimated ESL/storm surge heights\", \"units\": \"m\"}\n",
    ")\n",
    "out.wetland.attrs.update(\n",
    "    {\n",
    "        \"description\": \"Estimated area for all wetland by elevation\",\n",
    "        \"units\": \"km^2\",\n",
    "    }\n",
    ")\n",
    "out.wetlandservice.attrs.update(\n",
    "    {\n",
    "        \"description\": \"Value of wetlands\",\n",
    "        \"units\": f\"{dollar_units} per km^2\",\n",
    "    }\n",
    ")\n",
    "out.total_wetland_val.attrs.update(\n",
    "    {\n",
    "        \"description\": (\n",
    "            \"Estimated value for all wetland. Includes wetlands for segments that have \"\n",
    "            \"more wetland area than land area\"\n",
    "        ),\n",
    "        \"units\": dollar_units,\n",
    "    }\n",
    ")\n",
    "out.vsl.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Value of a Statistical Life\",\n",
    "        \"units\": f\"{dollar_units} per person\",\n",
    "    }\n",
    ")\n",
    "out.K_2000.attrs.update(\n",
    "    {\n",
    "        \"description\": \"Total value of capital in year 2000\",\n",
    "        \"units\": dollar_units,\n",
    "    }\n",
    ")\n",
    "out.K_scale.attrs.update(\n",
    "    {\n",
    "        \"description\": \"Ratio of capital stock in present year to K_2000\",\n",
    "        \"units\": dollar_units,\n",
    "    }\n",
    ")\n",
    "out.pop_2000.attrs.update({\"long_name\": \"Population in 2000\", \"units\": \"people\"})\n",
    "out.pop_scale.attrs.update(\n",
    "    {\n",
    "        \"description\": \"Ratio of population in present year to pop_2000\",\n",
    "        \"units\": dollar_units,\n",
    "    }\n",
    ")\n",
    "out.ypc.attrs.update(\n",
    "    {\n",
    "        \"description\": \"Downscaled income per capital\",\n",
    "        \"units\": f\"{dollar_units} per person\",\n",
    "    }\n",
    ")\n",
    "out.landarea.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Total Land Area\",\n",
    "        \"units\": \"km^2\",\n",
    "    }\n",
    ")\n",
    "out.interior.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Value of non-coastal land\",\n",
    "        \"units\": f\"{dollar_units} per km2\",\n",
    "    }\n",
    ")\n",
    "out.pc.attrs.update(\n",
    "    {\n",
    "        \"description\": \"Protection cost (quadratic with height)\",\n",
    "        \"units\": f\"{dollar_units} per km per vert m^2\",\n",
    "    }\n",
    ")\n",
    "out.mobcapfrac.attrs.update(\n",
    "    {\n",
    "        \"description\": \"Fraction of capital that is mobile\",\n",
    "    }\n",
    ")\n",
    "out.rho.attrs.update(\n",
    "    {\n",
    "        \"description\": (\n",
    "            \"Resilience factor scaling depth-damage and depth-mortality functions\"\n",
    "        )\n",
    "    }\n",
    ")\n",
    "out.lsl.attrs.update(\n",
    "    {\n",
    "        \"long_name\": \"Local Sea Level Rise\",\n",
    "        \"description\": (\n",
    "            \"Local Sea Level Rise under emissions scenario relative to 1991-2009 \"\n",
    "            \"baseline.\"\n",
    "        ),\n",
    "        \"units\": \"m\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# clear previously-saved zarr store encoding\n",
    "for d in out.data_vars:\n",
    "    out[d].encoding.clear()\n",
    "\n",
    "# prep str coords for zarr\n",
    "for k, v in out.coords.items():\n",
    "    if v.dtype == object:\n",
    "        out[k] = v.astype(\"unicode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7efd24d035f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save(out, PATH_DIAZ_INPUTS_INT, mode=\"w\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
