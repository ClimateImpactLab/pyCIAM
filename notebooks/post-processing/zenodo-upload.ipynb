{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ac0087-fe1b-4088-919e-ce007e6dea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706cee66-6557-402d-ae97-679ed202a9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a54dac-abdc-4a95-967f-2289fc1c9ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "from shutil import make_archive\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import dask.config\n",
    "import requests\n",
    "import shared\n",
    "from cloudpathlib import AnyPath\n",
    "from sliiders import settings as sset\n",
    "from zarr import ZipStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc342d12-c698-4f64-aaea-fcbfa027431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATT_OUTPUTS_NC = shared.PATH_OUTPUTS.parent / (shared.PATH_OUTPUTS.stem + \"_{case}.nc\")\n",
    "PATH_SLIIDERS_NC = sset.PATH_SLIIDERS.parent / (sset.PATH_SLIIDERS.stem + \".nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a125e75e-2122-4bd1-a994-37f1dbaea124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing noAdaptation\n",
      "Processing protect10\n",
      "Processing protect100\n",
      "Processing protect1000\n",
      "Processing protect10000\n",
      "Processing retreat1\n",
      "Processing retreat10\n",
      "Processing retreat100\n",
      "Processing retreat1000\n",
      "Processing retreat10000\n",
      "Processing optimalfixed\n"
     ]
    }
   ],
   "source": [
    "ds = shared.open_zarr(shared.PATH_OUTPUTS)\n",
    "fpaths = []\n",
    "for case in ds.case.values:\n",
    "    print(f\"Processing {case}\")\n",
    "    fpath = AnyPath(str(PATT_OUTPUTS_NC).format(case=case))\n",
    "    fpaths.append(fpath)\n",
    "    if not fpath.exists():\n",
    "        shared.save_dataset(ds.sel(case=case).load(), fpath)\n",
    "\n",
    "shared.save_dataset(shared.open_zarr(sset.PATH_SLIIDERS).load(), PATH_SLIIDERS_NC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d37ca26f-091d-4cb6-be02-385464e0b687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7d40ae7e1130>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler=\"threads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d9c67-f070-44a8-9594-e802e9be7c35",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a3e849-a554-49fa-882c-846acf76f3b8",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = \"Q5z5IQ1m5Z9l1QS7ZYeV78IS5bqPmhzcFVo0KSNLoh2p39HRMPgFoJsCyQt5\"\n",
    "VERSION = \"1.2.0\"\n",
    "TITLES = {\n",
    "    # \"SLIIDERS\": (\n",
    "    #     \"SLIIDERS: Sea Level Impacts Input Dataset by Elevation, Region, and Scenario\"\n",
    "    # ),\n",
    "    \"pyCIAM\": (\n",
    "        \"Estimates of Global Coastal Losses Under Multiple Sea Level Rise Scenarios\"\n",
    "    ),\n",
    "}\n",
    "PYCIAM_CODE_PATH = Path(\"pyCIAM.zip\")\n",
    "SLIIDERS_CODE_PATH = Path(\"/tmp/sliiders.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8725b84c-8a7f-4d88-96ec-849e963ef8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\"access_token\": ACCESS_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "956c40ee-e3e8-4257-bd0d-2c938546604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get host\n",
    "Z_URL = \"https://zenodo.org/api/deposit/depositions\"\n",
    "\n",
    "# Find existing depositions\n",
    "ALL_DEPOSITS = requests.get(\n",
    "    Z_URL,\n",
    "    params=PARAMS,\n",
    ").json()\n",
    "EXISTING_DEPOSITS = {}\n",
    "MISSING_DEPOSITS = []\n",
    "for k, v in TITLES.items():\n",
    "    this = [i for i in ALL_DEPOSITS if i[\"title\"] == v]\n",
    "    assert len(this) <= 1\n",
    "    if len(this):\n",
    "        EXISTING_DEPOSITS[k] = this[0]\n",
    "    else:\n",
    "        MISSING_DEPOSITS.append(k)\n",
    "assert not len(MISSING_DEPOSITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e92ff-f5c2-463b-8be0-62315620735c",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5fcb2b8-3fb4-4789-bae0-18f7a66b7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "AUTHORS = [\n",
    "    {\n",
    "        \"affiliation\": \"United Nations Development Programme\",\n",
    "        \"name\": \"Depsky, Nicholas\",\n",
    "        \"orcid\": \"0000-0002-9441-9042\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": (\n",
    "            \"Reask; Global Policy Lab, Goldman School of Public Policy, University of \"\n",
    "            \"California, Berkeley\"\n",
    "        ),\n",
    "        \"name\": \"Bolliger, Ian\",\n",
    "        \"orcid\": \"0000-0001-8055-297X\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Recidiviz\",\n",
    "        \"name\": \"Allen, Daniel\",\n",
    "        \"orcid\": \"0000-0001-5366-5178\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Columbia University\",\n",
    "        \"name\": \"Choi, Jun Ho\",\n",
    "        \"orcid\": \"0000-0003-0749-9222\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"The Rhodium Group\",\n",
    "        \"name\": \"Delgado, Michael\",\n",
    "        \"orcid\": \"0000-0002-2414-045X\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": (\n",
    "            \"National Bureau of Economic Research; Energy Policy Institute, University \"\n",
    "            \"of Chicago\"\n",
    "        ),\n",
    "        \"name\": \"Greenstone, Michael\",\n",
    "        \"orcid\": \"0000-0002-2364-2810\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"BlackRock\",\n",
    "        \"name\": \"Hamidi, Ali\",\n",
    "        \"orcid\": \"0000-0001-6235-0303\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"The Rhodium Group\",\n",
    "        \"name\": \"Houser, Trevor\",\n",
    "        \"orcid\": \"0000-0002-0514-7058\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": (\n",
    "            \"Global Policy Lab, Goldman School of Public Policy, University of \"\n",
    "            \"California, Berkeley; National Bureau of Economic Research\"\n",
    "        ),\n",
    "        \"name\": \"Hsiang, Solomon\",\n",
    "        \"orcid\": \"0000-0002-2074-0829\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": (\n",
    "            \"Department of Earth & Planetary Sciences and Rutgers Institute of Earth, \"\n",
    "            \"Ocean and Atmospheric Sciences, Rutgers University\"\n",
    "        ),\n",
    "        \"name\": \"Kopp, Robert E.\",\n",
    "        \"orcid\": \"0000-0003-4016-9428\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707918d-60c0-4a47-8adf-283ec7bdba42",
   "metadata": {},
   "source": [
    "## Files To Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55188020-c02f-4fa6-bf4c-cf1cd87e1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files and paths\n",
    "ORIGINAL_PATHS = {\n",
    "    \"SLIIDERS\": {\n",
    "        \"products\": [sset.PATH_SLIIDERS, PATH_SLIIDERS_NC],\n",
    "        \"inputs\": [\n",
    "            sset.PATH_GEOG_GTSM_SNAPPED,\n",
    "            sset.PATH_GEOG_GTSM_STATIONS_TOTHIN,\n",
    "            sset.PATH_SEG_PTS_MANUAL,\n",
    "        ],\n",
    "    },\n",
    "    # uncomment Diaz inputs if a re-upload is necessary\n",
    "    \"pyCIAM\": {\n",
    "        \"products\": [\n",
    "            shared.PATH_OUTPUTS,\n",
    "            # shared.PATH_DIAZ_RES,\n",
    "            shared.PATH_MOVEFACTOR_DATA,\n",
    "            *fpaths,\n",
    "        ],\n",
    "        \"inputs\": [\n",
    "            # shared.PATH_DIAZ_INPUTS_RAW,\n",
    "            # shared.PATH_SLR_AR5_QUANTILES,\n",
    "            shared.PATH_SLIIDERS_INCOME_INTERMEDIATE_FILE,\n",
    "            shared.PATHS_SURGE_LOOKUP[\"seg\"],\n",
    "            shared.PATHS_SURGE_LOOKUP[\"seg_adm\"],\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "if PYCIAM_CODE_PATH is not None:\n",
    "    ORIGINAL_PATHS[\"pyCIAM\"][\"source\"] = [PYCIAM_CODE_PATH]\n",
    "if SLIIDERS_CODE_PATH is not None:\n",
    "    ORIGINAL_PATHS[\"SLIIDERS\"][\"source\"] = [SLIIDERS_CODE_PATH]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff745dd-9688-44fe-9d19-0c12f7be9ab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and/or update depositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c10e4c-b3eb-4714-8d32-486ac878d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_draft_deposit(name, update_dict={}, overwrite=False):\n",
    "    dep = EXISTING_DEPOSITS[name]\n",
    "\n",
    "    # create new deposit if needed\n",
    "    r = requests.post(dep[\"links\"][\"newversion\"], params=PARAMS)\n",
    "    # case 1: this is already a new unpublished version\n",
    "    if (\n",
    "        r.status_code == 404\n",
    "        and r.json()[\"message\"] == \"The persistent identifier is not registered.\"\n",
    "    ):\n",
    "        pass\n",
    "    # case 2: this is a successful new version request and we need to grab the new\n",
    "    # version deposition\n",
    "    elif r.status_code in [200, 201]:\n",
    "        # returned value would be original deposit version in case of new version\n",
    "        # created\n",
    "        dep = r.json()\n",
    "    # case 3: some other error\n",
    "    else:\n",
    "        raise ValueError(f\"{r.status_code}: {r.text}\")\n",
    "\n",
    "    dep = requests.get(dep[\"links\"][\"latest_draft\"], params=PARAMS).json()\n",
    "\n",
    "    if overwrite:\n",
    "        new_id = dep[\"links\"][\"latest_draft\"].split(\"/\")[-1]\n",
    "        files = requests.get(dep[\"links\"][\"files\"], params=PARAMS).json()\n",
    "        if len(files):\n",
    "            for f in files:\n",
    "                file_url = f\"{Z_URL}/{new_id}/files/{f['id']}\"\n",
    "                r = requests.delete(file_url, params=PARAMS)\n",
    "                if r.status_code not in [204, 404]:\n",
    "                    raise ValueError(f\"{r.status_code}: {r.text}\")\n",
    "\n",
    "    metadata = {k: v for k, v in dep[\"metadata\"].copy().items() if k != \"doi\"}\n",
    "    metadata.update({\"version\": VERSION, **update_dict})\n",
    "    url = dep[\"links\"][\"latest_draft\"]\n",
    "    meta_put = requests.put(\n",
    "        url,\n",
    "        params=PARAMS,\n",
    "        data=json.dumps({\"metadata\": metadata}),\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    if meta_put.status_code != 200:\n",
    "        raise ValueError(f\"{meta_put.status_code}: {meta_put.text}\")\n",
    "    return dep\n",
    "\n",
    "\n",
    "def create_all_new_deposits(titles=TITLES, overwrite=False):\n",
    "    return {t: create_draft_deposit(t, overwrite=overwrite) for t in titles.keys()}\n",
    "\n",
    "\n",
    "def _get_zenodo_name(fname):\n",
    "    # drop a datestamp if it exists\n",
    "    zenodo_name = re.sub(r\"_\\d{8}\", \"\", fname.name)\n",
    "    # drop version from name\n",
    "    return \"-\".join([i for i in zenodo_name.split(\"-\") if shared.RES_VERS not in i])\n",
    "\n",
    "\n",
    "def upload_file(\n",
    "    deposit_link_dict, fname, zenodo_name=None, overwrite=False, existing_files={}\n",
    "):\n",
    "    if zenodo_name is None:\n",
    "        zenodo_name = _get_zenodo_name(fname)\n",
    "\n",
    "    if zenodo_name in existing_files:\n",
    "        if not overwrite:\n",
    "            print(\"...Skipping b/c already uploaded\")\n",
    "            return existing_files[zenodo_name]\n",
    "        requests.delete(existing_files[zenodo_name][\"links\"][\"self\"], params=PARAMS)\n",
    "\n",
    "    with fname.open(\"rb\") as fp:\n",
    "        r = requests.put(\n",
    "            f\"{deposit_link_dict['bucket']}/{zenodo_name}\",\n",
    "            params=PARAMS,\n",
    "            data=fp,\n",
    "        )\n",
    "\n",
    "    if r.status_code not in [200, 201]:\n",
    "        raise ValueError(f\"{r.status_code}: {r.text}\")\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def upload_file_list(deposit, flist, overwrite=False):\n",
    "    out = []\n",
    "    existing_file_request = requests.get(deposit[\"links\"][\"files\"], params=PARAMS)\n",
    "    if existing_file_request.status_code == 404:\n",
    "        existing_files = {}\n",
    "    else:\n",
    "        existing_files = {f[\"filename\"]: f for f in existing_file_request.json()}\n",
    "    for f in flist:\n",
    "        print(f\"Uploading: {str(f)}\")\n",
    "        zenodo_name = _get_zenodo_name(f)\n",
    "        if (\n",
    "            zenodo_name in existing_files or (zenodo_name + \".zip\") in existing_files\n",
    "        ) and not overwrite:\n",
    "            print(\"...Skipping b/c already uploaded\")\n",
    "            continue\n",
    "        if f.is_file():\n",
    "            out.append(\n",
    "                upload_file(\n",
    "                    deposit[\"links\"],\n",
    "                    f,\n",
    "                    overwrite=overwrite,\n",
    "                    zenodo_name=zenodo_name,\n",
    "                    existing_files=existing_files,\n",
    "                )\n",
    "            )\n",
    "        elif f.is_dir():\n",
    "            with TemporaryDirectory() as d:\n",
    "                tmp_file = Path(d) / (f.name + \".zip\")\n",
    "\n",
    "                if f.suffix == \".zarr\":\n",
    "                    with ZipStore(tmp_file, mode=\"w\") as tf:\n",
    "                        ds = shared.open_zarr(f)\n",
    "                        for c in ds.coords:\n",
    "                            ds[c].load()\n",
    "                            ds[c].encoding = {}\n",
    "                        for v in ds.variables:\n",
    "                            if ds[v].dtype == \"object\":\n",
    "                                ds[v] = ds[v].astype(\"unicode\")\n",
    "                        ds.to_zarr(tf)\n",
    "                else:\n",
    "                    name = Path(d) / f.name\n",
    "                    f.download_to(name)\n",
    "                    make_archive(name, \"zip\", name)\n",
    "\n",
    "                out.append(\n",
    "                    upload_file(\n",
    "                        deposit[\"links\"],\n",
    "                        tmp_file,\n",
    "                        zenodo_name=zenodo_name,\n",
    "                        overwrite=overwrite,\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(f)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "868b1d78-5eb4-4fa6-bcfc-0dbd8c88d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_deps = create_all_new_deposits(overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff8703bb-c630-418e-9f2f-c62b116ee7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyCIAM\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/sliiders/int/exposure/ypk/finalized/ypk_2000_2100_20240222.zarr\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/data/int/surge-lookup-v1.2-seg.zarr\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/data/int/surge-lookup-v1.2-seg_adm.zarr\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs.zarr\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/suboptimal_capital_by_movefactor.zarr\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_noAdaptation.nc\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_protect10.nc\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_protect100.nc\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_protect1000.nc\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_protect10000.nc\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_retreat1.nc\n",
      "...Skipping b/c already uploaded\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_retreat10.nc\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_retreat100.nc\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_retreat1000.nc\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.2/pyCIAM_outputs_optimalfixed.nc\n",
      "Uploading: pyCIAM.zip\n"
     ]
    }
   ],
   "source": [
    "uploads = {}\n",
    "for name in TITLES:\n",
    "    print(name)\n",
    "    kind = ORIGINAL_PATHS[name]\n",
    "    this_dep = draft_deps[name]\n",
    "\n",
    "    uploads[name] = []\n",
    "    for filetype in [\"inputs\", \"products\", \"source\"]:\n",
    "        if filetype in kind:\n",
    "            uploads[name] += upload_file_list(this_dep, kind[filetype], overwrite=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
