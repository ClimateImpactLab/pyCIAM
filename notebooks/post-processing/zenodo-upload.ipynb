{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ac0087-fe1b-4088-919e-ce007e6dea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "706cee66-6557-402d-ae97-679ed202a9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a54dac-abdc-4a95-967f-2289fc1c9ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from shutil import make_archive\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import dask.config\n",
    "import requests\n",
    "import shared\n",
    "import xarray as xr\n",
    "from sliiders import settings as sset\n",
    "from sliiders.io import open_zarr\n",
    "from zarr import ZipStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f804bd08-6edb-43f6-8bbd-7a2b98281c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_SLIIDERS_NC = sset.PATH_SLIIDERS.parent / (sset.PATH_SLIIDERS.stem + \".nc\")\n",
    "PATH_OUTPUTS_NC = shared.PATH_OUTPUTS.parent / (shared.PATH_OUTPUTS.stem + \".nc\")\n",
    "\n",
    "shared.save_dataset(shared.open_zarr(sset.PATH_SLIIDERS).load(), PATH_SLIIDERS_NC)\n",
    "shared.save_dataset(shared.open_zarr(sset.PATH_OUTPUTS).load(), PATH_OUTPUTS_NC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d37ca26f-091d-4cb6-be02-385464e0b687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x7cfe44438890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler=\"threads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d9c67-f070-44a8-9594-e802e9be7c35",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55a3e849-a554-49fa-882c-846acf76f3b8",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = \"Q5z5IQ1m5Z9l1QS7ZYeV78IS5bqPmhzcFVo0KSNLoh2p39HRMPgFoJsCyQt5\"\n",
    "VERSION = \"1.2.0\"\n",
    "TITLES = {\n",
    "    \"SLIIDERS\": \"SLIIDERS: Sea Level Impacts Input Dataset by Elevation, Region, and Scenario\",\n",
    "    # \"pyCIAM\": \"Estimates of Global Coastal Losses Under Multiple Sea Level Rise Scenarios\",\n",
    "}\n",
    "PYCIAM_CODE_PATH = Path(\"pyCIAM-1.1.2.zip\")\n",
    "SLIIDERS_CODE_PATH = Path(\"/tmp/sliiders-1.2.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8725b84c-8a7f-4d88-96ec-849e963ef8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\"access_token\": ACCESS_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "956c40ee-e3e8-4257-bd0d-2c938546604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get host\n",
    "Z_URL = \"https://zenodo.org/api/deposit/depositions\"\n",
    "\n",
    "# Find existing depositions\n",
    "ALL_DEPOSITS = requests.get(\n",
    "    Z_URL,\n",
    "    params=PARAMS,\n",
    ").json()\n",
    "EXISTING_DEPOSITS = {}\n",
    "MISSING_DEPOSITS = []\n",
    "for k, v in TITLES.items():\n",
    "    this = [i for i in ALL_DEPOSITS if i[\"title\"] == v]\n",
    "    assert len(this) <= 1\n",
    "    if len(this):\n",
    "        EXISTING_DEPOSITS[k] = this[0]\n",
    "    else:\n",
    "        MISSING_DEPOSITS.append(k)\n",
    "assert not len(MISSING_DEPOSITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e92ff-f5c2-463b-8be0-62315620735c",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5fcb2b8-3fb4-4789-bae0-18f7a66b7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "AUTHORS = [\n",
    "    {\n",
    "        \"affiliation\": \"Energy & Resources Group, University of California, Berkeley; Global Policy Lab, Goldman School of Public Policy, University of California, Berkeley\",\n",
    "        \"name\": \"Depsky, Nicholas\",\n",
    "        \"orcid\": \"0000-0002-9441-9042\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"BlackRock; Global Policy Lab, Goldman School of Public Policy, University of California, Berkeley\",\n",
    "        \"name\": \"Bolliger, Ian\",\n",
    "        \"orcid\": \"0000-0001-8055-297X\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Global Policy Lab, Goldman School of Public Policy, University of California, Berkeley\",\n",
    "        \"name\": \"Allen, Daniel\",\n",
    "        \"orcid\": \"0000-0001-5366-5178\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Energy Policy Institute, University of Chicago\",\n",
    "        \"name\": \"Choi, Jun Ho\",\n",
    "        \"orcid\": \"0000-0003-0749-9222\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"The Rhodium Group\",\n",
    "        \"name\": \"Delgado, Michael\",\n",
    "        \"orcid\": \"0000-0002-2414-045X\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"National Bureau of Economic Research; Energy Policy Institute, University of Chicago\",\n",
    "        \"name\": \"Greenstone, Michael\",\n",
    "        \"orcid\": \"0000-0002-2364-2810\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"The Rhodium Group\",\n",
    "        \"name\": \"Hamidi, Ali\",\n",
    "        \"orcid\": \"0000-0001-6235-0303\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"The Rhodium Group\",\n",
    "        \"name\": \"Houser, Trevor\",\n",
    "        \"orcid\": \"0000-0002-0514-7058\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Global Policy Lab, Goldman School of Public Policy, University of California, Berkeley; National Bureau of Economic Research\",\n",
    "        \"name\": \"Hsiang, Solomon\",\n",
    "        \"orcid\": \"0000-0002-2074-0829\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Department of Earth & Planetary Sciences and Rutgers Institute of Earth, Ocean and Atmospheric Sciences, Rutgers University\",\n",
    "        \"name\": \"Kopp, Robert E.\",\n",
    "        \"orcid\": \"0000-0003-4016-9428\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707918d-60c0-4a47-8adf-283ec7bdba42",
   "metadata": {},
   "source": [
    "## Files To Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55188020-c02f-4fa6-bf4c-cf1cd87e1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files and paths\n",
    "ORIGINAL_PATHS = {\n",
    "    \"SLIIDERS\": {\n",
    "        \"products\": [sset.PATH_SLIIDERS, PATH_SLIIDERS_NC],\n",
    "        \"inputs\": [\n",
    "            sset.PATH_GEOG_GTSM_SNAPPED,\n",
    "            sset.PATH_GEOG_GTSM_STATIONS_TOTHIN,\n",
    "            sset.PATH_SEG_PTS_MANUAL,\n",
    "        ],\n",
    "    },\n",
    "    \"pyCIAM\": {\n",
    "        \"products\": [\n",
    "            shared.PATH_OUTPUTS,\n",
    "            PATH_OUTPUTS_NC,\n",
    "            shared.PATH_DIAZ_RES,\n",
    "            shared.PATH_MOVEFACTOR_DATA,\n",
    "        ],\n",
    "        \"inputs\": [\n",
    "            shared.PATH_DIAZ_INPUTS_RAW,\n",
    "            shared.PATH_SLR_AR5_QUANTILES,\n",
    "            shared.PATH_SLIIDERS_INCOME_INTERMEDIATE_FILE,\n",
    "            shared.PATHS_SURGE_LOOKUP[\"seg\"],\n",
    "            shared.PATHS_SURGE_LOOKUP[\"seg_adm\"],\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "if PYCIAM_CODE_PATH is not None:\n",
    "    ORIGINAL_PATHS[\"pyCIAM\"][\"source\"] = [PYCIAM_CODE_PATH]\n",
    "if SLIIDERS_CODE_PATH is not None:\n",
    "    ORIGINAL_PATHS[\"SLIIDERS\"][\"source\"] = [SLIIDERS_CODE_PATH]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff745dd-9688-44fe-9d19-0c12f7be9ab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and/or update depositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50c10e4c-b3eb-4714-8d32-486ac878d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_draft_deposit(name, update_dict={}, overwrite=False):\n",
    "    dep = EXISTING_DEPOSITS[name]\n",
    "    # create new deposit\n",
    "    deposition_id = dep[\"id\"]\n",
    "    if \"latest_draft\" not in dep[\"links\"]:\n",
    "        url = f\"{Z_URL}/{deposition_id}/actions/newversion\"\n",
    "        r = requests.post(url, params=PARAMS)\n",
    "        if r.status_code not in [200, 201]:\n",
    "            raise ValueError(f\"{r.status_code}: {r.text}\")\n",
    "        dep = r.json()\n",
    "\n",
    "    if overwrite:\n",
    "        new_id = dep[\"links\"][\"latest_draft\"].split(\"/\")[-1]\n",
    "        files = requests.get(dep[\"links\"][\"files\"], params=PARAMS).json()\n",
    "        print(files)\n",
    "        if len(files):\n",
    "            for f in files:\n",
    "                file_url = f\"{Z_URL}/{new_id}/files/{f['id']}\"\n",
    "                r = requests.delete(file_url, params=PARAMS)\n",
    "                if r.status_code not in [204, 404]:\n",
    "                    raise ValueError(f\"{r.status_code}: {r.text}\")\n",
    "\n",
    "    metadata = {k: v for k, v in dep[\"metadata\"].copy().items() if k != \"doi\"}\n",
    "    metadata.update({\"version\": VERSION, **update_dict})\n",
    "    url = dep[\"links\"][\"latest_draft\"]\n",
    "    meta_put = requests.put(\n",
    "        url,\n",
    "        params=PARAMS,\n",
    "        data=json.dumps({\"metadata\": metadata}),\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    if meta_put.status_code != 200:\n",
    "        raise ValueError(f\"{meta_put.status_code}: {meta_put.text}\")\n",
    "    return dep\n",
    "\n",
    "\n",
    "def create_all_new_deposits(titles=TITLES, overwrite=False):\n",
    "    deps = {}\n",
    "    ids = {}\n",
    "    for t in titles.keys():\n",
    "        dep = create_draft_deposit(t, overwrite=overwrite)\n",
    "        ids[t] = int(dep[\"links\"][\"latest_draft\"].split(\"/\")[-1])\n",
    "    all_deps = requests.get(\n",
    "        Z_URL,\n",
    "        params={\"access_token\": ACCESS_TOKEN},\n",
    "    ).json()\n",
    "    for t in titles.keys():\n",
    "        dep = [d for d in all_deps if d[\"id\"] == ids[t]]\n",
    "        assert len(dep) == 1\n",
    "        deps[t] = dep[0]\n",
    "    return deps\n",
    "\n",
    "\n",
    "def upload_file(deposit_link_dict, fname, root, zenodo_name=None, overwrite=False):\n",
    "    if zenodo_name is None:\n",
    "        zenodo_name = fname.name\n",
    "    zenodo_name = root + zenodo_name\n",
    "\n",
    "    existing_files = {\n",
    "        f[\"filename\"]: f\n",
    "        for f in requests.get(deposit_link_dict[\"files\"], params=PARAMS).json()\n",
    "    }\n",
    "    if zenodo_name in existing_files:\n",
    "        if not overwrite:\n",
    "            print(\"...Skipping b/c already uploaded\")\n",
    "            return existing_files[zenodo_name]\n",
    "        requests.delete(existing_files[zenodo_name][\"links\"][\"self\"], params=PARAMS)\n",
    "\n",
    "    with fname.open(\"rb\") as fp:\n",
    "        r = requests.put(\n",
    "            f\"{deposit_link_dict['bucket']}/{zenodo_name}\",\n",
    "            params=PARAMS,\n",
    "            data=fp,\n",
    "        )\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        raise ValueError(f\"{r.status_code}: {r.text}\")\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def upload_file_list(deposit, flist, root, overwrite=False):\n",
    "    out = []\n",
    "    existing_files = {\n",
    "        f[\"filename\"]: f\n",
    "        for f in requests.get(deposit[\"links\"][\"files\"], params=PARAMS).json()\n",
    "    }\n",
    "    for f in flist:\n",
    "        print(f\"Uploading: {str(f)}\")\n",
    "        if (\n",
    "            (root + f.name) in existing_files\n",
    "            or (root + f.name + \".zip\") in existing_files\n",
    "        ) and not overwrite:\n",
    "            print(\"...Skipping b/c already uploaded\")\n",
    "            continue\n",
    "        if f.is_file():\n",
    "            out.append(upload_file(deposit[\"links\"], f, root, overwrite=overwrite))\n",
    "        elif f.is_dir():\n",
    "            with TemporaryDirectory() as d:\n",
    "                tmp_file = Path(d) / (f.name + \".zip\")\n",
    "\n",
    "                if f.suffix == \".zarr\":\n",
    "                    with ZipStore(tmp_file, mode=\"w\") as tf:\n",
    "                        ds = shared.open_zarr(f)\n",
    "                        for c in ds.coords:\n",
    "                            ds[c].load()\n",
    "                            ds[c].encoding = {}\n",
    "                        for v in ds.variables:\n",
    "                            if ds[v].dtype == \"object\":\n",
    "                                ds[v] = ds[v].astype(\"unicode\")\n",
    "                        ds.to_zarr(tf)\n",
    "                else:\n",
    "                    name = Path(d) / f.name\n",
    "                    f.download_to(name)\n",
    "                    make_archive(name, \"zip\", name)\n",
    "\n",
    "                out.append(\n",
    "                    upload_file(\n",
    "                        deposit[\"links\"],\n",
    "                        tmp_file,\n",
    "                        root,\n",
    "                        overwrite=overwrite,\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(f)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "868b1d78-5eb4-4fa6-bcfc-0dbd8c88d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_deps = create_all_new_deposits(overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e67ba-77cb-4355-9dfb-d11533f1a344",
   "metadata": {},
   "source": [
    "Note that it seems to take some time for the \"bucket\" link to show up, which is needed to use Zenodo's \"new\" file API, which allows for uploads larger than 100MB. So if bucket is not appearing, you may need to wait a while (<1 day) to be able to run the file uploads below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff8703bb-c630-418e-9f2f-c62b116ee7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLIIDERS\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[1;32m      4\u001b[0m this_dep \u001b[38;5;241m=\u001b[39m draft_deps[name]\n\u001b[0;32m----> 6\u001b[0m uploads[name] \u001b[38;5;241m=\u001b[39m \u001b[43mupload_file_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis_dep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m uploads[name] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m upload_file_list(\n\u001b[1;32m     10\u001b[0m     this_dep, kind[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproducts\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproducts/\u001b[39m\u001b[38;5;124m\"\u001b[39m, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kind\u001b[38;5;241m.\u001b[39mkeys():\n",
      "Cell \u001b[0;32mIn[40], line 83\u001b[0m, in \u001b[0;36mupload_file_list\u001b[0;34m(deposit, flist, root, overwrite)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupload_file_list\u001b[39m(deposit, flist, root, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m     out \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 83\u001b[0m     existing_files \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilename\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeposit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlinks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfiles\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPARAMS\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m flist:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[40], line 84\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupload_file_list\u001b[39m(deposit, flist, root, overwrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     82\u001b[0m     out \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     83\u001b[0m     existing_files \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m---> 84\u001b[0m         \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilename\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m: f\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mget(deposit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinks\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles\u001b[39m\u001b[38;5;124m\"\u001b[39m], params\u001b[38;5;241m=\u001b[39mPARAMS)\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     86\u001b[0m     }\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m flist:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(f)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "uploads = {}\n",
    "for name, kind in ORIGINAL_PATHS.items():\n",
    "    print(name)\n",
    "    this_dep = draft_deps[name]\n",
    "\n",
    "    uploads[name] = upload_file_list(\n",
    "        this_dep, kind[\"inputs\"], \"inputs/\", overwrite=False\n",
    "    )\n",
    "    uploads[name] += upload_file_list(\n",
    "        this_dep, kind[\"products\"], \"products/\", overwrite=False\n",
    "    )\n",
    "    if \"source\" in kind.keys():\n",
    "        uploads[name] += upload_file_list(\n",
    "            this_dep, kind[\"source\"], \"source/\", overwrite=False\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
