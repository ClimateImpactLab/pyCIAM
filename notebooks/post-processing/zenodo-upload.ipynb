{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "706cee66-6557-402d-ae97-679ed202a9fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a54dac-abdc-4a95-967f-2289fc1c9ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from os import environ\n",
    "from pathlib import Path\n",
    "from shutil import make_archive\n",
    "from tempfile import TemporaryDirectory\n",
    "from pathlib import Path\n",
    "\n",
    "import dask.config\n",
    "import requests\n",
    "import shared\n",
    "from sliiders import settings as sset\n",
    "from zarr import ZipStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37ca26f-091d-4cb6-be02-385464e0b687",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x112a25b70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dask.config.set(scheduler=\"threads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d9c67-f070-44a8-9594-e802e9be7c35",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a3e849-a554-49fa-882c-846acf76f3b8",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = environ[\"ACCESS_TOKEN\"]\n",
    "VERSION = \"1.1.0\"\n",
    "TITLES = {\n",
    "    \"SLIIDERS\": \"SLIIDERS: Sea Level Impacts Input Dataset by Elevation, Region, and Scenario\",\n",
    "    \"pyCIAM\": \"Estimates of Global Coastal Losses Under Multiple Sea Level Rise Scenarios\",\n",
    "}\n",
    "PYCIAM_CODE_PATH=Path(\"pyCIAM-1.1.2.zip\")\n",
    "SLIIDERS_CODE_PATH=Path(\"sliiders-1.1.1.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8725b84c-8a7f-4d88-96ec-849e963ef8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\"access_token\": ACCESS_TOKEN}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "956c40ee-e3e8-4257-bd0d-2c938546604d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get host\n",
    "Z_URL = \"https://zenodo.org/api/deposit/depositions\"\n",
    "\n",
    "# Find existing depositions\n",
    "ALL_DEPOSITS = requests.get(\n",
    "    Z_URL,\n",
    "    params=PARAMS,\n",
    ").json()\n",
    "EXISTING_DEPOSITS = {}\n",
    "MISSING_DEPOSITS = []\n",
    "for k, v in TITLES.items():\n",
    "    this = [i for i in ALL_DEPOSITS if i[\"title\"] == v]\n",
    "    assert len(this) <= 1\n",
    "    if len(this):\n",
    "        EXISTING_DEPOSITS[k] = this[0]\n",
    "    else:\n",
    "        MISSING_DEPOSITS.append(k)\n",
    "assert not len(MISSING_DEPOSITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e92ff-f5c2-463b-8be0-62315620735c",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fcb2b8-3fb4-4789-bae0-18f7a66b7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata\n",
    "AUTHORS = [\n",
    "    {\n",
    "        \"affiliation\": \"Energy & Resources Group, University of California, Berkeley; Global Policy Lab, Goldman School of Public Policy, University of California, Berkeley\",\n",
    "        \"name\": \"Depsky, Nicholas\",\n",
    "        \"orcid\": \"0000-0002-9441-9042\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"BlackRock; Global Policy Lab, Goldman School of Public Policy, University of California, Berkeley\",\n",
    "        \"name\": \"Bolliger, Ian\",\n",
    "        \"orcid\": \"0000-0001-8055-297X\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Global Policy Lab, Goldman School of Public Policy, University of California, Berkeley\",\n",
    "        \"name\": \"Allen, Daniel\",\n",
    "        \"orcid\": \"0000-0001-5366-5178\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Energy Policy Institute, University of Chicago\",\n",
    "        \"name\": \"Choi, Jun Ho\",\n",
    "        \"orcid\": \"0000-0003-0749-9222\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"The Rhodium Group\",\n",
    "        \"name\": \"Delgado, Michael\",\n",
    "        \"orcid\": \"0000-0002-2414-045X\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"National Bureau of Economic Research; Energy Policy Institute, University of Chicago\",\n",
    "        \"name\": \"Greenstone, Michael\",\n",
    "        \"orcid\": \"0000-0002-2364-2810\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"The Rhodium Group\",\n",
    "        \"name\": \"Hamidi, Ali\",\n",
    "        \"orcid\": \"0000-0001-6235-0303\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"The Rhodium Group\",\n",
    "        \"name\": \"Houser, Trevor\",\n",
    "        \"orcid\": \"0000-0002-0514-7058\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Global Policy Lab, Goldman School of Public Policy, University of California, Berkeley; National Bureau of Economic Research\",\n",
    "        \"name\": \"Hsiang, Solomon\",\n",
    "        \"orcid\": \"0000-0002-2074-0829\",\n",
    "    },\n",
    "    {\n",
    "        \"affiliation\": \"Department of Earth & Planetary Sciences and Rutgers Institute of Earth, Ocean and Atmospheric Sciences, Rutgers University\",\n",
    "        \"name\": \"Kopp, Robert E.\",\n",
    "        \"orcid\": \"0000-0003-4016-9428\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707918d-60c0-4a47-8adf-283ec7bdba42",
   "metadata": {},
   "source": [
    "## Files To Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55188020-c02f-4fa6-bf4c-cf1cd87e1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files and paths\n",
    "ORIGINAL_PATHS = {\n",
    "    \"SLIIDERS\": {\n",
    "        \"products\": [shared.PATH_SLIIDERS],\n",
    "        \"inputs\": [\n",
    "            sset.PATH_GEOG_GTSM_SNAPPED,\n",
    "            sset.PATH_GEOG_GTSM_STATIONS_TOTHIN,\n",
    "            sset.PATH_SEG_PTS_MANUAL,\n",
    "        ],\n",
    "    },\n",
    "    \"pyCIAM\": {\n",
    "        \"products\": [\n",
    "            shared.PATH_OUTPUTS,\n",
    "            shared.PATH_DIAZ_RES,\n",
    "            shared.PATH_MOVEFACTOR_DATA,\n",
    "        ],\n",
    "        \"inputs\": [\n",
    "            shared.PATH_DIAZ_INPUTS_RAW,\n",
    "            shared.PATH_SLR_AR5_QUANTILES,\n",
    "            shared.PATH_SLIIDERS_INCOME_INTERMEDIATE_FILE,\n",
    "            shared.PATHS_SURGE_LOOKUP[\"seg\"],\n",
    "            shared.PATHS_SURGE_LOOKUP[\"seg_adm\"],\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "\n",
    "if PYCIAM_CODE_PATH is not None:\n",
    "    ORIGINAL_PATHS[\"pyCIAM\"][\"source\"] = [PYCIAM_CODE_PATH]\n",
    "if SLIIDERS_CODE_PATH is not None:\n",
    "    ORIGINAL_PATHS[\"SLIIDERS\"][\"source\"] = [SLIIDERS_CODE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff745dd-9688-44fe-9d19-0c12f7be9ab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create and/or update depositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c10e4c-b3eb-4714-8d32-486ac878d041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_draft_deposit(name, update_dict={}, overwrite=False):\n",
    "    dep = EXISTING_DEPOSITS[name]\n",
    "    # create new deposit\n",
    "    deposition_id = dep[\"id\"]\n",
    "    if deposition_id == int(dep[\"links\"][\"latest\"].split(\"/\")[-1]):\n",
    "        url = f\"{Z_URL}/{deposition_id}/actions/newversion\"\n",
    "        r = requests.post(url, params=PARAMS)\n",
    "        if r.status_code not in [200, 201]:\n",
    "            raise ValueError(f\"{r.status_code}: {r.text}\")\n",
    "        dep = r.json()\n",
    "\n",
    "    if overwrite:\n",
    "        new_id = dep[\"links\"][\"latest_draft\"].split(\"/\")[-1]\n",
    "        files = requests.get(dep[\"links\"][\"files\"], params=PARAMS).json()\n",
    "        print(files)\n",
    "        if len(files):\n",
    "            for f in files:\n",
    "                file_url = f\"{Z_URL}/{new_id}/files/{f['id']}\"\n",
    "                r = requests.delete(file_url, params=PARAMS)\n",
    "                if r.status_code not in [204, 404]:\n",
    "                    raise ValueError(f\"{r.status_code}: {r.text}\")\n",
    "\n",
    "    metadata = {k: v for k, v in dep[\"metadata\"].copy().items() if k != \"doi\"}\n",
    "    metadata.update({\"version\": VERSION, **update_dict})\n",
    "    url = dep[\"links\"][\"latest_draft\"]\n",
    "    meta_put = requests.put(\n",
    "        url,\n",
    "        params=PARAMS,\n",
    "        data=json.dumps({\"metadata\": metadata}),\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    if meta_put.status_code != 200:\n",
    "        raise ValueError(f\"{meta_put.status_code}: {meta_put.text}\")\n",
    "    return dep\n",
    "\n",
    "\n",
    "def create_all_new_deposits(titles=TITLES, overwrite=False):\n",
    "    deps = {}\n",
    "    ids = {}\n",
    "    for t in titles.keys():\n",
    "        dep = create_draft_deposit(t, overwrite=overwrite)\n",
    "        ids[t] = int(dep[\"links\"][\"latest_draft\"].split(\"/\")[-1])\n",
    "    all_deps = requests.get(\n",
    "        Z_URL,\n",
    "        params={\"access_token\": ACCESS_TOKEN},\n",
    "    ).json()\n",
    "    for t in titles.keys():\n",
    "        dep = [d for d in all_deps if d[\"id\"] == ids[t]]\n",
    "        assert len(dep) == 1\n",
    "        deps[t] = dep[0]\n",
    "    return deps\n",
    "\n",
    "\n",
    "def upload_file(deposit_link_dict, fname, root, zenodo_name=None, overwrite=False):\n",
    "    if zenodo_name is None:\n",
    "        zenodo_name = fname.name\n",
    "    zenodo_name = root + zenodo_name\n",
    "\n",
    "    existing_files = {\n",
    "        f[\"filename\"]: f\n",
    "        for f in requests.get(deposit_link_dict[\"files\"], params=PARAMS).json()\n",
    "    }\n",
    "    if zenodo_name in existing_files:\n",
    "        if not overwrite:\n",
    "            print(\"...Skipping b/c already uploaded\")\n",
    "            return existing_files[zenodo_name]\n",
    "        requests.delete(existing_files[zenodo_name][\"links\"][\"self\"], params=PARAMS)\n",
    "\n",
    "    with fname.open(\"rb\") as fp:\n",
    "        r = requests.put(\n",
    "            f\"{deposit_link_dict['bucket']}/{zenodo_name}\",\n",
    "            params=PARAMS,\n",
    "            data=fp,\n",
    "        )\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        raise ValueError(f\"{r.status_code}: {r.text}\")\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def upload_file_list(deposit, flist, root, overwrite=False):\n",
    "    out = []\n",
    "    existing_files = {\n",
    "        f[\"filename\"]: f\n",
    "        for f in requests.get(deposit[\"links\"][\"files\"], params=PARAMS).json()\n",
    "    }\n",
    "    for f in flist:\n",
    "        print(f\"Uploading: {str(f)}\")\n",
    "        if (\n",
    "            (root + f.name) in existing_files\n",
    "            or (root + f.name + \".zip\") in existing_files\n",
    "        ) and not overwrite:\n",
    "            print(\"...Skipping b/c already uploaded\")\n",
    "            continue\n",
    "        if f.is_file():\n",
    "            out.append(upload_file(deposit[\"links\"], f, root, overwrite=overwrite))\n",
    "        elif f.is_dir():\n",
    "            with TemporaryDirectory() as d:\n",
    "                tmp_file = Path(d) / (f.name + \".zip\")\n",
    "\n",
    "                if f.suffix == \".zarr\":\n",
    "                    with ZipStore(tmp_file, mode=\"w\") as tf:\n",
    "                        ds = shared.open_zarr(f)\n",
    "                        for c in ds.coords:\n",
    "                            ds[c].load()\n",
    "                            ds[c].encoding = {}\n",
    "                        for v in ds.variables:\n",
    "                            if ds[v].dtype == \"object\":\n",
    "                                ds[v] = ds[v].astype(\"unicode\")\n",
    "                        ds.to_zarr(tf)\n",
    "                else:\n",
    "                    name = Path(d) / f.name\n",
    "                    f.download_to(name)\n",
    "                    make_archive(name, \"zip\", name)\n",
    "\n",
    "                out.append(\n",
    "                    upload_file(\n",
    "                        deposit[\"links\"],\n",
    "                        tmp_file,\n",
    "                        root,\n",
    "                        overwrite=overwrite,\n",
    "                    )\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(f)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "868b1d78-5eb4-4fa6-bcfc-0dbd8c88d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_deps = create_all_new_deposits(overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e67ba-77cb-4355-9dfb-d11533f1a344",
   "metadata": {},
   "source": [
    "Note that it seems to take some time for the \"bucket\" link to show up, which is needed to use Zenodo's \"new\" file API, which allows for uploads larger than 100MB. So if bucket is not appearing, you may need to wait a while (<1 day) to be able to run the file uploads below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff8703bb-c630-418e-9f2f-c62b116ee7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyCIAM\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/sliiders/raw/CIAM_2016/diaz2016_inputs_raw.zarr\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/data/int/slr/ar5/ar5-msl-rel-2005-quantiles.zarr\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/sliiders/int/exposure/ypk/finalized/ypk_2000_2100_20221122.zarr\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/data/int/surge-lookup-v1.1-seg.zarr\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/data/int/surge-lookup-v1.1-seg_adm.zarr\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.1/pyCIAM_outputs.zarr\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.1/diaz2016_outputs.zarr\n",
      "Uploading: gs://rhg-data/impactlab-rhg/coastal/ciam_paper/results-v1.1/suboptimal_capital_by_movefactor.zarr\n"
     ]
    }
   ],
   "source": [
    "uploads = {}\n",
    "for name, kind in ORIGINAL_PATHS.items():\n",
    "    print(name)\n",
    "    this_dep = draft_deps[name]\n",
    "\n",
    "    uploads[name] = upload_file_list(\n",
    "        this_dep, kind[\"inputs\"], \"inputs/\", overwrite=False\n",
    "    )\n",
    "    uploads[name] += upload_file_list(\n",
    "        this_dep, kind[\"products\"], \"products/\", overwrite=False\n",
    "    )\n",
    "    if \"source\" in kind.keys(): \n",
    "        uploads[name] += upload_file_list(\n",
    "            this_dep, kind[\"source\"], \"source/\", overwrite=False\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sliiders]",
   "language": "python",
   "name": "conda-env-sliiders-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
